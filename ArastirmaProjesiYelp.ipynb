{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                Çeşitli Makine Öğrenimi Algoritmaları Kullanılarak Yelp Veri Kümesindeki İnceleme Derecelerinin Tahmini ve Duyarlılık Analizi\n",
    "                                \n",
    "\n",
    "                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerekli kütüphaneleri yükleyelim. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pandas, veri okuma, veri ön işleme ve veri temizleme işlemlerinde kullanılır. \n",
    "- numpy matematiksel işlevler için kullanılır. \n",
    "- matplotlib.pyplot, veri görselleştirme için kullanılır. \n",
    "- seaborn, matplotlib kütüphanesine yüksek seviye arayüz sağlayan bir kütüphanedir. \n",
    "- nltk, doğal dil işleme paketidir. \n",
    "- stopwords, stopwords için kullanılır. \n",
    "- string, string işlemleri için kullanılır. \n",
    "- math, matematiksel işlemler yapmak için kullanılır. \n",
    "- CountVectorizer, cümleleri vektörleştirmek için scikit-learn kütüphanesi tarafından sağlanır. her cümlenin kelimelerini alır ve cümledeki tüm benzersiz kelimelerin bir sözlüğünü oluşturur.\n",
    "- train_test_split, dizileri veya matrisleri rastgele train ve test alt kümelerine bölmek için kullanılır. \n",
    "- classification_report, doğruluk, kesinlik ve duyarlılık metriklerini ayrı ayrı kod yazmadan gösterir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('D:/TEZ/yelp.csv') #data yı yükledik "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veri Kümesinin İncelenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri kümesinin satır ve sütun sayısı\n",
      "(10000, 10)\n",
      "Satır isimleri:\n",
      "Index(['business_id', 'date', 'review_id', 'stars', 'text', 'type', 'user_id',\n",
      "       'cool', 'useful', 'funny'],\n",
      "      dtype='object')\n",
      "Her sütunun veri türü:\n",
      "business_id    object\n",
      "date           object\n",
      "review_id      object\n",
      "stars           int64\n",
      "text           object\n",
      "type           object\n",
      "user_id        object\n",
      "cool            int64\n",
      "useful          int64\n",
      "funny           int64\n",
      "dtype: object\n",
      "Birkaç veri seti girişi::\n",
      "              business_id        date               review_id  stars  \\\n",
      "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
      "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
      "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
      "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
      "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
      "\n",
      "                                                text    type  \\\n",
      "0  My wife took me here on my birthday for breakf...  review   \n",
      "1  I have no idea why some people give bad review...  review   \n",
      "2  love the gyro plate. Rice is so good and I als...  review   \n",
      "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
      "4  General Manager Scott Petello is a good egg!!!...  review   \n",
      "\n",
      "                  user_id  cool  useful  funny  \n",
      "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
      "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
      "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
      "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
      "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4174</td>\n",
       "      <td>1995</td>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9998</td>\n",
       "      <td>1</td>\n",
       "      <td>6403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ntN85eu27C04nwyPa8IHtw</td>\n",
       "      <td>2011-03-28</td>\n",
       "      <td>uxhJaxosyQfFDUdIg_jbaQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This review is for the chain in general. The l...</td>\n",
       "      <td>review</td>\n",
       "      <td>fczQCSmaWF78toLEmb0Zsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>37</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>10000</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.777500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.876800</td>\n",
       "      <td>1.409300</td>\n",
       "      <td>0.701300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.214636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.067861</td>\n",
       "      <td>2.336647</td>\n",
       "      <td>1.907942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id        date               review_id  \\\n",
       "count                    10000       10000                   10000   \n",
       "unique                    4174        1995                   10000   \n",
       "top     ntN85eu27C04nwyPa8IHtw  2011-03-28  uxhJaxosyQfFDUdIg_jbaQ   \n",
       "freq                        37          21                       1   \n",
       "mean                       NaN         NaN                     NaN   \n",
       "std                        NaN         NaN                     NaN   \n",
       "min                        NaN         NaN                     NaN   \n",
       "25%                        NaN         NaN                     NaN   \n",
       "50%                        NaN         NaN                     NaN   \n",
       "75%                        NaN         NaN                     NaN   \n",
       "max                        NaN         NaN                     NaN   \n",
       "\n",
       "               stars                                               text  \\\n",
       "count   10000.000000                                              10000   \n",
       "unique           NaN                                               9998   \n",
       "top              NaN  This review is for the chain in general. The l...   \n",
       "freq             NaN                                                  2   \n",
       "mean        3.777500                                                NaN   \n",
       "std         1.214636                                                NaN   \n",
       "min         1.000000                                                NaN   \n",
       "25%         3.000000                                                NaN   \n",
       "50%         4.000000                                                NaN   \n",
       "75%         5.000000                                                NaN   \n",
       "max         5.000000                                                NaN   \n",
       "\n",
       "          type                 user_id          cool        useful  \\\n",
       "count    10000                   10000  10000.000000  10000.000000   \n",
       "unique       1                    6403           NaN           NaN   \n",
       "top     review  fczQCSmaWF78toLEmb0Zsw           NaN           NaN   \n",
       "freq     10000                      38           NaN           NaN   \n",
       "mean       NaN                     NaN      0.876800      1.409300   \n",
       "std        NaN                     NaN      2.067861      2.336647   \n",
       "min        NaN                     NaN      0.000000      0.000000   \n",
       "25%        NaN                     NaN      0.000000      0.000000   \n",
       "50%        NaN                     NaN      0.000000      1.000000   \n",
       "75%        NaN                     NaN      1.000000      2.000000   \n",
       "max        NaN                     NaN     77.000000     76.000000   \n",
       "\n",
       "               funny  \n",
       "count   10000.000000  \n",
       "unique           NaN  \n",
       "top              NaN  \n",
       "freq             NaN  \n",
       "mean        0.701300  \n",
       "std         1.907942  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         1.000000  \n",
       "max        57.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veri kümesini incelemek \n",
    "\n",
    "# VERİNİN SATIR VE SÜTUN SAYISI\n",
    "\n",
    "print(\"Veri kümesinin satır ve sütun sayısı\")\n",
    "print(data.shape)\n",
    "\n",
    "# SATIR İSİMLERİ \n",
    "\n",
    "print(\"Satır isimleri:\")\n",
    "print(data.columns)\n",
    "\n",
    "# HER SÜTUNUN VERİ TÜRÜ \n",
    "\n",
    "print(\"Her sütunun veri türü:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# BİRKAÇ VERİSETİ GÖRMEK \n",
    "\n",
    "print(\"Birkaç veri seti girişi::\")\n",
    "print(data.head())\n",
    "\n",
    "# DATASET SUMMARY\n",
    "\n",
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İncelemenin (text değişkeninin) kelime uzunluğunu içeren \"length\" isimli yeni bir değişken oluşturalım. Bunu apply(len) işlevi ile yapacağız. Bu işlev, verilen dize, dizi, liste, demet, sözlük vb. uzunluğunu almak için kullanılır. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  length  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0     889  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0    1345  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0      76  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0     419  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0     469  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['length'] = data['text'].apply(len)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yıldızlar ile incelemenin uzunluğu (length) arasında herhangi bir ilişki olup olmadığını görselleştirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x152117fcc40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = sns.FacetGrid(data=data,col='stars') # seaborn kütüphanesindeki FacetGrid nesnesi ile boş bir grid oluşturduk  \n",
    "\n",
    "graph.map(plt.hist,'length',bins=50,color='purple') # graph.map yaklaşımı ile grid üzerine histogram oluşturduk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='stars', ylabel='length'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=\"stars\", y=\"length\", data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yıldız sayısı ile inceleme uzunluğu arasında doğru bir orantı olduğunu görmekteyiz. Müşterilerin yalnızca olumlu olarak etkilendiklerinde detaylı incelemeler yaptığını düşünmek mantıklıdır. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veride, diğer kullanıcıların incelemelere bıraktıkları \"cool\" \"useful\" ve\"funny\" (havalı, kullanışlı ve komik) ifadeleri bulunmakta. Bu bir kullanıcının yaptığı incelemeye diğer kullanıcıların nasıl bir yaklaşım sergiledikleri hakkında fikrimiz olması açısından yararlıdır.\n",
    "\n",
    "Şimdi incelemeye verilen yıldızları gruplayarak yıldızlara göre bu üç ifadenin ortalama değerini bulalım. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stars</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.576769</td>\n",
       "      <td>1.604806</td>\n",
       "      <td>1.056075</td>\n",
       "      <td>826.515354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.719525</td>\n",
       "      <td>1.563107</td>\n",
       "      <td>0.875944</td>\n",
       "      <td>842.256742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.788501</td>\n",
       "      <td>1.306639</td>\n",
       "      <td>0.694730</td>\n",
       "      <td>758.498289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.954623</td>\n",
       "      <td>1.395916</td>\n",
       "      <td>0.670448</td>\n",
       "      <td>712.923142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.944261</td>\n",
       "      <td>1.381780</td>\n",
       "      <td>0.608631</td>\n",
       "      <td>624.999101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cool    useful     funny      length\n",
       "stars                                          \n",
       "1      0.576769  1.604806  1.056075  826.515354\n",
       "2      0.719525  1.563107  0.875944  842.256742\n",
       "3      0.788501  1.306639  0.694730  758.498289\n",
       "4      0.954623  1.395916  0.670448  712.923142\n",
       "5      0.944261  1.381780  0.608631  624.999101"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stval = data.groupby('stars').mean() # veriyi yıldızlara göre gruplayıp ortalama değerini bulduk. \n",
    "\n",
    "stval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sonuçta şu yorumları yapmak mantıklı olacaktır, \n",
    "\n",
    "- Bütün yıldızların ortalama \"useful\" değeri yakın ancak en düşük üç yıldız değeri çıkmıştır. Bu sebeple bütün incelemeler diğer kullanıcılar tarafından yararlı bulunmuştur ancak en az yararlı bulunan yorumlar genel olarak üç yıldız verilerek yapılan yorumlardır. \n",
    "\n",
    "\n",
    "- Bir yıldız verilerek yapılan incelemerin ortalama \"funny\" değeri diğer yıldızlara göre yüksek ancak ortalama \"cool\" değeri ise en düşük çıkmıştır. Bu sebeple bir yıldız veren kullanıcı yorumları diğer yorumlara göre daha komik ancak en az havalı bulunmuştur. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, Useful ve Funny değerleri arasındaki korelasyona bakalım. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cool</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.743329</td>\n",
       "      <td>-0.944939</td>\n",
       "      <td>-0.857664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>useful</th>\n",
       "      <td>-0.743329</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894506</td>\n",
       "      <td>0.699881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>-0.944939</td>\n",
       "      <td>0.894506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.843461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <td>-0.857664</td>\n",
       "      <td>0.699881</td>\n",
       "      <td>0.843461</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cool    useful     funny    length\n",
       "cool    1.000000 -0.743329 -0.944939 -0.857664\n",
       "useful -0.743329  1.000000  0.894506  0.699881\n",
       "funny  -0.944939  0.894506  1.000000  0.843461\n",
       "length -0.857664  0.699881  0.843461  1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stval.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Böylece \n",
    "\n",
    "Aşağıdakiler arasında negatif korelasyonun var olduğunu görebiliriz:\n",
    "\n",
    "- Cool ve Useful\n",
    "- Cool ve Funny\n",
    "- Cool ve Length\n",
    "\n",
    "Bu nedenle, cool olarak işaretlenen incelemelerin kısa olma eğiliminde olduğunu, başkaları için pek yararlı olmadığını ve komik bulunmadığını söyleyebiliriz. \n",
    "\n",
    "Aşağıdakiler arasında ise pozitif bir korelasyon vardır: \n",
    "\n",
    "- Funny ve Useful    \n",
    "- Funny ve Length\n",
    "- Useful ve Length  \n",
    "\n",
    "Bu nedenle, daha uzun incelemelerin eğlenceli ve faydalı olma eğiliminde olduğunu söyleyebiliriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veri kümesini sınıflandırmak, incelemelere ve yıldızlara bölmek \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yelp veri çerçevesinin sütunlarını içeren, ancak yalnızca 1, 3 veya 5 yıldızlı incelemeler için data_classes adında bir veri çerçevesi oluşturalım ve yeni veriye head() fonksiyonu ile bir göz atalım. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zp713qNhx8d9KCJJnrw1xA</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>riFQ3vxNpP4rWLk_CSri2A</td>\n",
       "      <td>5</td>\n",
       "      <td>Drop what you're doing and drive here. After I...</td>\n",
       "      <td>review</td>\n",
       "      <td>wFweIWhv2fREZV_dYkz_1g</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "6  zp713qNhx8d9KCJJnrw1xA  2010-02-12  riFQ3vxNpP4rWLk_CSri2A      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "6  Drop what you're doing and drive here. After I...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  length  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0     889  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0    1345  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0     419  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0     469  \n",
       "6  wFweIWhv2fREZV_dYkz_1g     7       7      4    1565  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_classes = data[(data['stars']==1) | (data['stars']==3) | (data['stars']==5)]\n",
    "\n",
    "data_classes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeni verinin satır ve sütun sayılarına bakalım. \n",
    "\n",
    "\"shape\" işlevi, bir dizinin şeklini döndürür. Shape bir tamsayı demetidir. Bu sayılar, karşılık gelen dizi boyutunun uzunluklarını belirtir. Başka bir deyişle: Bir dizinin \"şekli\", eksen (boyut) başına eleman sayısını içeren bir tanımlama grubudur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5547, 11)\n"
     ]
    }
   ],
   "source": [
    "print(data_classes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Görüldüğü gibi 1000 satır 5547 'e  düşmüştür."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1 - Features**\n",
    "\n",
    "Makine öğreniminin kökleri istatistiksel analizlere dayanır. Bu sebeple, makine öğrenimindeki kavramları istatistikteki karşılıklarına bakarak anlamak genellikle oldukça basittir.\n",
    "\n",
    "İstatistikte, belirli bir istatistiksel birim ile ilişkili özellikleri gösteren \"variables\" (değişkenler) hakkında konuşurken, Makine öğreniminde \"Features\" (özellikler) hakkında konuşuruz. \n",
    "\n",
    "İki disiplinin terminolojisinin çok benzer olduğunu görebiliriz ve genellikle birinden veya diğerinden gelen terimleri birbirinin yerine kullanmak mümkündür. Böylece özelliklerin değişkenlerin benzeri olduğunu söyleyebiliriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kavramın anlamını sezgisel olarak anlamak için gözlemlerin özelliklerini belirlemeye çalıştığımız birkaç senaryo görelim.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Özellikleri kavramsallaştırmanın kolay bir yolu, bunların bazı sensör ölçümlerinin sonucu olduğunu hayal etmektir. Her on beş dakikada bir havanın sıcaklığını kaydeden bir termometremiz olduğunu düşünelim. Kaydettikten sonra, bir kağıda yazarsak:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.baeldung.com/wp-content/uploads/sites/4/2020/07/thermometer.png\" width=\"300\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='https://www.baeldung.com/wp-content/uploads/sites/4/2020/07/thermometer.png', width=300, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Termometre, sonucu bir gözlem tablosu oluşturan ölçümler gerçekleştirir. **Her ölçümle ilişkili değer, istatistiksel analizde makine öğrenimi terminolojisine sahip bir \"sıcaklık\" özelliğine veya bir özelliğe karşılık gelir.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Başka bir senaryo düşünelim. Bir polis radarı, arabaların caddede gitme hızını ölçer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.baeldung.com/wp-content/uploads/sites/4/2020/07/cars-768x472-1.png\" width=\"300\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='https://www.baeldung.com/wp-content/uploads/sites/4/2020/07/cars-768x472-1.png', width=300, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sonuç, her satırın bir aracın plakasını ve radar tarafından ölçülen o aracın hızını içeren bir bilgisayardaki bir dosyadır.\n",
    "\n",
    "Bu bağlamda plakalar veri setinin ID veya indeksini, hız ise özellikleri oluşturmaktadır. Bununla birlikte, belirli bir caddeyi hangi arabaların kullandığını öğrenmek istiyorsak, plakaları sadece indeksler olarak değil, özellikler olarak kullanmamıza izin verilir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gördüğümüz örnekler bize **“özellik” terimini bir gözlem veya ölçümün sonucunu yansıtmak için kullandığımızı gösteriyor.** Neyin bir ölçüm oluşturduğuna dair özel bir kısıtlama yoktur. Sonuç olarak, yeni bir göreve yaklaşırken, normal olarak, onunla ilgili ölçümler yapmamıza izin verecek şekilde onu tanımlamak için biraz zaman harcamamız gerekir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features (Özellik) Sınıfları**\n",
    "\n",
    "Bununla birlikte, kendimizi yönlendirmek için takip edebileceğimiz özelliklerin seçimiyle ilgili bazı ortak buluşsal yöntemler vardır. Bunlardan biri, belirli bir görev için uygun olan özellik sınıfının tanımlanmasını içerir. \n",
    "\n",
    "Features, bir platformdan veya dilden diğerine biraz değişen çeşitli türlerde veya sınıflarda olabilir. Genel programlama dilleri için en yaygın veri türlerinin tümü, özellikler için geçerli sınıflardır. Bunlar:\n",
    "\n",
    "- Tamsayılar, kayan sayılar ve **gerçek sayıların diğer hesaplanabilir yaklaşımları**\n",
    "\n",
    "\n",
    "- \"Merhaba dünya\" gibi önceden işlenmiş **metin dizeleri**\n",
    "\n",
    "\n",
    "- Nominal ve sıralı kategorilere ayırdığımız **kategoriler**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gerçek Sayıların Yaklaşımı**\n",
    "\n",
    "Makine öğrenimi veri kümelerindeki en yaygın özellik, integers, floats, doubles veya gerçek sayılara yaklaşan diğer ilkel veri türlerinden oluşur. Bunlar, belirli bir aletle yaptığımız nicel ölçümlerin sonuçlarıdır.\n",
    "\n",
    "Sayısal veri türleri, makine öğrenmesinde en sık kullanılan özelliklerdir. Sonuç olarak, çoğu makine öğrenme tekniği onlara uygulanabilir.\n",
    "\n",
    "Bu tekniklerden biri örneğin lineer regresyondur. Hedef değişkenin değerini tahmin etmek için sayısal bir özellik kullanarak doğrusal regresyon gerçekleştirebiliriz. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metin dizeleri**\n",
    "\n",
    "Makine öğrenimi görevleri için başka bir tipik özellik, metin veya daha doğrusu bir dize nesnesidir. Dizeler, makine öğrenimi için Doğal Dil İşleme (Natural Language Processing) alt sektöründe kullanılan birincil özelliktir.\n",
    "\n",
    "Metinleri makine öğrenimi uygulamaları için özellikler olarak ele alma şeklimiz, sayısal özelliklerde olduğu kadar doğrudan değildir. Aslında metinleri doğrudan özellik olarak ele almak ve aynı zamanda bir metin corpusundan yararlı bir şey çıkarmak mümkün değildir. Bunun iki ana nedeni vardır. \n",
    "\n",
    "**Birincisi kombinatorik ile ilgili.** Bir dizgedeki her karakteri, alfabenin 26 harfinden birinin değerini alabilen rastgele bir değişken olarak ele almaya çalışabiliriz. Bunu yapsaydık, n uzunluğundaki her dize 26^n olası değerden birini alabilirdi, bu da arama alanını hızlı bir şekilde yönetilemez hale getirir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.baeldung.com/wp-content/ql-cache/quicklatex.com-e5d62d27cd7ad739c7c66522fcfe3d1e_l3.svg\" width=\"150\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='https://www.baeldung.com/wp-content/ql-cache/quicklatex.com-e5d62d27cd7ad739c7c66522fcfe3d1e_l3.svg', width=150, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ve bu argüman boşlukları veya diğer karakterleri dikkate almaz. **İkinci neden, metinlerin sanıldığı kadar yüksek olmayan bilgi içeriği ile ilgilidir.** Bu bağlamda, aşağıdaki metinler corpus 'unu ele alalım:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.baeldung.com/wp-content/ql-cache/quicklatex.com-d9a4c3c0a1e48a37e0f165767fc0ec60_l3.svg\" width=\"200\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='https://www.baeldung.com/wp-content/ql-cache/quicklatex.com-d9a4c3c0a1e48a37e0f165767fc0ec60_l3.svg', width=200, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metinlerin bir kalem ve bir masadan bahsettiğini bildiğimizi varsayarsak, o zaman kelimelerin çoğunun ne kadar yararlı bilgiler içermediğini görebiliriz. Aslında aynı corpus'u daha indirgenmiş bir biçimde tanımlayabiliriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.baeldung.com/wp-content/ql-cache/quicklatex.com-869bec011acaf6ea51204014a1477771_l3.svg\" width=\"160\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='https://www.baeldung.com/wp-content/ql-cache/quicklatex.com-869bec011acaf6ea51204014a1477771_l3.svg', width=160, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu, daha genel bir kural için özel bir durumdur: Metinler doğrudan özellik olarak kullanılmazlar, ancak bir tür ön işleme tabi tutulduktan sonra kullanılırlar. Bu ön işleme adımları, normal olarak, kök çıkarma ve lemmatizasyonun yanı sıra tokenizasyon ve vektörleştirmeyi içerir. Önceden işlenmiş metinler daha sonra veri madenciliği için özellikler(features) haline gelir, ancak orijinal formlarındaki metinler özellik değildir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kategorik Özellikler**\n",
    "\n",
    "Biraz daha zorlayıcı bir kavram, kategorik değerler veya özelliklerdir. Kategorilerin ardındaki fikir, dünyayı bölümlere ayırabilmemiz ve birbirini dışlayan sınıflara bölebilmemizdir. Bu fikri, birden çok bağlama nasıl uygulandığını görerek daha iyi anlayabiliriz.\n",
    "\n",
    "Örnek olarak, belirli bir hasattaki elmaların rengini örneklediğimizi düşünelim:\n",
    "\n",
    "Yeşil olan bir elmanın da kırmızı olmadığını ve bunun tersinin de tüm renk kombinasyonları için geçerli olduğunu güvenle söyleyebiliriz. Sonuç olarak “elmanın rengi” özelliğinin kategorik bir özellik olduğunu söyleyebiliriz. Bunlar için belirli bir tercih sıramız olmadığı için bu kategorilerin sırasız olduğunu da varsayabiliriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2 - Labels** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makine öğrenimine giriş metinlerinde, bir veri kümesinin özelliklerini bir modelin girdisi olarak ve aynı veri kümesinin etiketlerini (labels) de modelin çıktısı olarak düşünmek yaygındır. Ancak bu yaklaşımın genelleme kapasitesini sınırlayan iki önemli sorunu vardır:\n",
    "\n",
    "- etiketler normalde biz herhangi bir makine öğrenimi modelini oluşturmadan ve hatta tanımlamadan önce atanır.\n",
    "\n",
    "\n",
    "- etiketler, özellikle bağımsızlıklarını sorguladığımız ve doğrulamak istediğimizde bazı modellere girdi olarak kullanılabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Targets (Hedef) Olarak Labels (Etiketler)**\n",
    "\n",
    "Bir label, bir anlamda, keyfi olarak yüksek önem atadığımız bir veri kümesindeki bir özelliktir. Hisse senedi fiyatlarındaki değişimi ve hepsinin ait olduğu portföyün fiyatındaki değişimi incelediğimizi düşünelim: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.baeldung.com/wp-content/ql-cache/quicklatex.com-2070bdccd83b5f5072bc401f386a8815_l3.svg\" width=\"240\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='https://www.baeldung.com/wp-content/ql-cache/quicklatex.com-2070bdccd83b5f5072bc401f386a8815_l3.svg', width=240, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu göreve bakmanın bir yolu, portföyün fiyatının, içerdiği hisse senetlerinin fiyatına bağlı olduğunu hayal etmektir. Eğer teorik beklentimiz buysa, o zaman portföy = f(hisse senetleri) formunun bir fonksiyonunu inceleyebiliriz.\n",
    "\n",
    "Daha sonra bu işlevi denetimli öğrenme yoluyla modellemeye çalışabiliriz. Bu bağlamda, hisse senedi fiyatını özellik, portföy fiyatını da etiket olarak ele alırız.\n",
    "\n",
    "Aynı derecede iyi bir yaklaşım, portföyün fiyatının, içerdiği hisse senetlerinin fiyatını etkilediğini hayal etmek olacaktır. Bu süreci, bir öncekinin tersi olan stoklar = g(portföy) fonksiyonu ile modelleyebiliriz. Bu bağlamda portföyün fiyatı tek özellik olacak ve hisse senedi fiyatları modelimizde beş etiket olacaktır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi, anlatılanlara göre Yelp veri çerçevesinin sütunlarını içeren, ancak yalnızca 1, 3 veya 5 yıldızlı incelemeler içeren data_classes 'dan x ve y olmak üzere iki nesne oluşturalım. X, data_classes'ın *'metin'* sütunu yani özellikler(features) olacak ve y, data_classes'ın *'yıldızlar'* sütunu yani labels(etiketler) olacak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_classes['text']\n",
    "y = data_classes['stars']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x ve y verilerine head() fonksiyonu ile bakalım. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    My wife took me here on my birthday for breakf...\n",
      "1    I have no idea why some people give bad review...\n",
      "3    Rosie, Dakota, and I LOVE Chaparral Dog Park!!...\n",
      "4    General Manager Scott Petello is a good egg!!!...\n",
      "6    Drop what you're doing and drive here. After I...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5\n",
      "1    5\n",
      "3    5\n",
      "4    5\n",
      "6    5\n",
      "Name: stars, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stop words**\n",
    "\n",
    "Doğal bir dil işlenmeden önce genellikle filtreden geçirilen kelimelere stop words denir. Bunlar aslında herhangi bir dilde (makaleler, edatlar, zamirler, bağlaçlar vb.) en yaygın kelimelerdir ve metne fazla bilgi eklemez. İngilizce'deki birkaç stop words'e örnek olarak “the”, “a”, “an”, “so”, “what” verilebilir. \n",
    "\n",
    "**Stop words neden temizlenir?**\n",
    "\n",
    "Stop words herhangi bir dilde bolca mevcuttur. Bu kelimeleri kaldırarak, önemli bilgilere daha fazla odaklanmak için metnimizden düşük seviyeli bilgileri çıkarıyoruz. Sırayla, bu tür kelimelerin çıkarılmasının, görevimiz için eğittiğimiz model üzerinde herhangi bir olumsuz sonuç göstermediğini söyleyebiliriz.\n",
    "\n",
    "Stop words'ün kaldırılması, veri kümesi boyutunu kesinlikle azaltır ve dolayısıyla trainde yer alan daha az sayıda belirteç nedeniyle train süresini azaltır.\n",
    "\n",
    "**Stop words her zaman temizlenir mi? Bizim için her zaman işe yaramazlar mı?**\n",
    "\n",
    "Stop words her zaman temizlenmez.Stop words 'ün kaldırılması, büyük ölçüde gerçekleştirdiğimiz göreve ve ulaşmak istediğimiz hedefe bağlıdır. Örneğin, duygu analizi görevini gerçekleştirebilecek bir model eğitiyorsak, stop words 'ü kaldıramayabiliriz.\n",
    "\n",
    "Örneğin, Bir **Film incelemesi: “Film hiç iyi değildi.”** olsun.\n",
    "\n",
    "Stop words 'ün kaldırılmasından sonraki metin: **\"film iyi\"**\n",
    "\n",
    "Film için yapılan incelemenin olumsuz olduğunu açıkça görebiliyoruz. Ancak, stop kelimelerinin kaldırılmasından sonra inceleme olumlu oldu, ki bu gerçek değil. Bu nedenle, burada durma sözcüklerinin kaldırılması sorunlu olabilir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi, stopwords ve noktalama işaretlerini kaldırarak veri setini temizleyecek bir fonksiyon tanımlayacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vektörleştirme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CountVectorizer**\n",
    "\n",
    "Tahmine dayalı modelleme için metin verilerini kullanmak için, metnin belirli kelimeleri kaldıracak şekilde ayrıştırılması gerekir - bu işleme belirteçleme denir . Bu kelimelerin daha sonra makine öğrenimi algoritmalarında girdi olarak kullanılmak üzere tamsayılar veya kayan nokta değerleri olarak kodlanması gerekir. Bu işleme, özellik çıkarma (veya **vektörleştirme**) denir .\n",
    "\n",
    "Scikit-learn kütüphanesindeki **CountVectorizer**, bir metin dokümanı koleksiyonunu bir terim / simge sayısı vektörüne dönüştürmek için kullanılır. Aynı zamanda, vektör gösterimini oluşturmadan önce metin verilerinin önceden işlenmesini sağlar. Bu işlevsellik, onu metin için oldukça esnek bir özellik temsil modülü yapar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scikit-Learn'ün vektörleştiricileri hakkında**\n",
    "\n",
    "Bildiğiniz gibi makineler, ne kadar gelişmiş olursa olsun, kelimeleri ve cümleleri insanlarla aynı şekilde anlayamaz. Belgelerin külliyatını bilgisayarlar için daha çekici hale getirmek için, önce sayısal bir yapıya dönüştürülmesi gerekir. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag-of-Words (BoW)** , bu soruna çok sezgisel bir yaklaşımdır ve yöntemler şunları içerir:\n",
    "\n",
    "**1. Bir tür kalıp izleyerek belgeleri tokenlara ayırmak.**\n",
    "\n",
    "Tokenlara ayırma, gereksiz sık kullanılan kelimelerin (stop-words) atılması ve kelime köklerini bulma(stemming) en yaygın kullanılan ön işleme yöntemlerindendir.\n",
    "\n",
    "Bir metin dokümanını analiz etmek için, ilk olarak tokenlara ayırma işlemi yapılmalı ve kelime grupları elde edilmelidir.\n",
    "Tüm ortak ayırıcılar, işleçler, noktalama işaretleri ve yazdırılamayan karakterler kaldırılır.\n",
    "Daha sonra, en sık kullanılan kelimeleri filtrelemeyi amaçlayan stop-words filtreleme gerçekleştirilir. Örnek olarak: “ama, belki, acaba”.\n",
    "\n",
    "Son olarak, kelime hakkında dil-bilgisel veya sözcüksel bilgiler sunan son-eklerin çıkarılmasıyla morfolojik kökün elde edilmesini amaçlayan stemming ve / veya lemmatization uygulanır. Bu araştırmada, bu adım atlanmıştır.\n",
    "\n",
    "**2. Her tokena, belgede ve / veya külliyatta görünme sıklığıyla orantılı bir ağırlık atamak.**\n",
    "\n",
    "Her satırın bir belgeyi temsil ettiği ve her bir sütunun bir belirteci ele aldığı bir belge terim matrisi oluşturulur.\n",
    "\n",
    "Scikit-Learn tarafından sağlanan vektörleştirici nesneleri, kutudan çıkar çıkmaz oldukça güvenilirdir, yukarıdaki tüm adımları aynı anda verimli bir şekilde gerçekleştirmemize ve hatta token sayısı ve sıklığı ile ilgili ön işleme ve kuralları uygulamamıza izin verir. Hepsinden önemlisi, üç farklı sürüme sahiptirler (DictVectorizers gibi başka sürümler de vardır, ancak o kadar yaygın değildir):\n",
    "\n",
    "**Count Vectorizer :** Bir tokenın belgede kaç kez göründüğünü sayar ve bu değeri ağırlığı olarak kullanır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer'ı içe aktarıp ve bir CountVectorizer nesnesi oluşturacağız. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fit_transform()**\n",
    "\n",
    "fit_transform(), train verilerini ölçekleyebilmemiz ve ayrıca bu verilerin ölçekleme parametrelerini öğrenebilmemiz için train verilerinde kullanılır. Fit yöntemi, verilerimizde bulunan özelliklerin her birinin ortalamasını ve varyansını hesaplıyor. Dönüştürme yöntemi, ilgili ortalama ve varyansı kullanarak tüm özellikleri dönüştürüyor.\n",
    "\n",
    "CountVectorizer nesnesinde fit_transform yöntemini kullanalım ve x'i ('metin' sütunu) iletelim. x'in üzerine yazarak bu sonucu kaydedelim. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "lower not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-53b68179e92f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1198\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1199\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \"\"\"\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: lower not found"
     ]
    }
   ],
   "source": [
    "x = cv.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verileri train ve test kümesine bölmek:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bunun için train_test_split işlevi kullanalım. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-18627f3511fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m101\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelleme**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi hangisinin en iyi performansı verdiğini görmek için birden fazla Makine Algoritması kullanacağız."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1- Multinomial (Çok Terimli) Naive Bayes** \n",
    "\n",
    "Çok terimli Naive Bayes algoritması, çoğunlukla Doğal Dil İşleme'de (NLP) kullanılan olasılıksal bir öğrenme yöntemidir. Algoritma Bayes teoremine dayanır ve bir e-posta veya gazete makalesi gibi bir metnin etiketini tahmin eder. Belirli bir örnek için her etiketin olasılığını hesaplar ve ardından çıktı olarak en yüksek olasılığa sahip etiketi verir.\n",
    "\n",
    "Naive Bayes sınıflandırıcı, tüm algoritmaların ortak bir ilkeyi paylaştığı ve sınıflandırılan her bir özelliğin başka bir özellikle ilgili olmadığı birçok algoritmanın bir koleksiyonudur. Bir özelliğin varlığı veya yokluğu, diğer özelliğin varlığını veya yokluğunu etkilemez.\n",
    "\n",
    "\n",
    "**Multinomial Naive Bayes nasıl çalışır?** \n",
    "\n",
    "Naive Bayes, metin madenciliği için ve birden çok sınıfla ilgili problemlerde kullanılan güçlü bir algoritmadır. Naive Bayes teoreminin işleyişini anlamak için önce Bayes teoremi kavramını anlamak önemlidir. \n",
    "\n",
    "Thomas Bayes tarafından formüle edilen Bayes teoremi, bir olayla ilgili koşulların ön bilgisine dayanarak bir olayın meydana gelme olasılığını hesaplar. Aşağıdaki formüle dayanmaktadır:\n",
    "\n",
    "**P(A|B) = P(A) * P(B|A)/P(B)**\n",
    "\n",
    "P(A) terimine A için önsel olasılık veya marjinal olasılık adı verilir. Bu önseldir, çünkü B olayı hakkında önceden herhangi bir bilgiyi içermemektedir.\n",
    "\n",
    "P(A|B) terimi verilmiş B için Anın koşullu olasılığı adını alır.\n",
    "\n",
    "P(B|A) terimi verilmiş A için Bnin koşullu olasılığı adını taşır.\n",
    "\n",
    "P(B) terimi B olayı için 'önsel' olasılıktır veya Bnin marjinal olasılığıdır ve matematiksel rolü normalize eden bir sabittir.\n",
    "Bu şekildeki Bayes teoremini, fazla matematiksel olmadan, sezgiye dayanarak şöyle açıklayabiliriz: Bayes teoremi eğer B gözlemlenmis ise, A gözlemi hakkındaki inançların ne şekilde güncelleştirilebileceğini ortaya çıkartır.\n",
    "\n",
    "Bu formül, metindeki etiketlerin olasılığını hesaplamaya yardımcı olur.\n",
    "\n",
    "- Gauss yerine Multinomial Naive Bayes kullanıyoruz çünkü seyrek(sparse) verilerle Gauss Naive Bayes varsayımları karşılanmaz ve veriler üzerinde basit bir gauss uyumu bize iyi bir uyum veya tahmin sağlamaz.\n",
    "\n",
    "(not: seyrek veri, değerlerin çoğunun sıfır olduğu anlamına gelir.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi Multinomial modeli MultinomialNB() fonksiyonu ile tanımlayıp eğiteceğiz. Ve ardından training setleri fit edeceğiz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions**\n",
    "\n",
    "Test setini tahmin etmek için oluşturduğumuz mnb modelinde predict metodunu kullanacağız. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predmnb = mnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi bu tahminleri ve y_test'i kullanarak bir confusion matrisi ve sınıflandırma raporu oluşturacağız. \n",
    "\n",
    "- Bir sınıflandırma algoritmasından tahminlerin kalitesini ölçmek için bir sınıflandırma raporu(Classification Report) kullanılır. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy classification score** \n",
    "\n",
    "Çoklu  etiket sınıflandırmasında, bu işlev alt küme doğruluğunu hesaplar: bir numune için tahmin edilen etiket kümesi, y_true içindeki karşılık gelen etiket kümesiyle tam olarak eşleşmelidir.\n",
    "\n",
    "*Açık hali şu şekildedir:*\n",
    "\n",
    "sklearn.metrics.accuracy_score(y_true, y_pred, *, normalize=True, sample_weight=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes için Confusion Matrix :\n",
      "[[ 75  49  38]\n",
      " [  7 180 105]\n",
      " [ 12  45 599]]\n",
      "Score: 76.94\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.46      0.59       162\n",
      "           3       0.66      0.62      0.64       292\n",
      "           5       0.81      0.91      0.86       656\n",
      "\n",
      "    accuracy                           0.77      1110\n",
      "   macro avg       0.75      0.66      0.69      1110\n",
      "weighted avg       0.77      0.77      0.76      1110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Multinomial Naive Bayes için Confusion Matrix :\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Accuracy -** En sezgisel performans ölçüsüdür ve sadece doğru tahmin edilen gözlemin toplam gözlemlere oranıdır. Doğruluğumuz yüksekse modelimizin en iyisi olduğu düşünülebilir. Ancak tek başına yeterli değildir, özellikle eşit dağılmayan unbiased veri kümelerinde model doğruluğu tek başına yeterli değildir. Örneğin kanser olan ve olmayan hastaların olduğu 100 kişilik bir veri kümemiz olduğunu düşünelim. Tüm hastalar içinde sadece 10 tanesinde kanser teşhisi konulmuştur. Böyle bir durumda kanser olan ancak teşhis edilemeyen (False Negative) hastalar olmasını istemeyiz. Bu nedenle diğer metriklerin sonuçlarını da birlikte değerlendirmeliyiz.\n",
    "\n",
    "   *Accuracy değeri, 0.77 çıkmıştır. Score ise 76.94 çıkmıştır* \n",
    "    \n",
    "\n",
    "- **Precision -** Tahminlerinizin yüzde kaçı doğru çıktı? \n",
    "Doğru tahmin edilen Positive gözlemlerin toplam tahmin edilen Positive gözlemlere oranıdır. Precision değeri özellikle False Positive tahminlemenin maliyeti yüksek olduğu durumlarda çok önemlidir. Örneğin mail kutunuza gelmesi gereken mailleri eğer modeliniz spam olarak işaretlerse (FP) bu durumda almanız gereken önemli mailleri görememiş olur ve sizin için kayıp yaratan bir durumda kalırsınız. Bu durumda Kesinlik değerinin yüksek olması bizim için model seçiminde önemli bir kriterdir. \n",
    "   \n",
    "   **True Positives/(True Positives + False Positives) şeklinde hesaplanır.**\n",
    "   \n",
    "   *Precision değeri en yüksek üçüncü modelde 0.81 olarak çıkmıştır ancak birinci model ile arasında fazla fark yoktur.* \n",
    "   \n",
    " \n",
    "- **Recall (Sensitivity) -** Pozitif vakaların yüzde kaçını yakaladınız? Positive olarak tahmin etmemiz gereken işlemlerin ne kadarını Positive olarak tahmin ettiğimizi gösteren bir metriktir. Sensitivity değeri de False Negative olarak tahminlemenin maliyetinin yüksek olduğu durumlarda bize yardımcı olacak bir metriktir. Mümkün olduğunca yüksek olması gereklidir. \n",
    "\n",
    "    **True Positives/(True Positives + False Negatives) şeklinde hesaplanır.**\n",
    "\n",
    "    *Sensitivity değeri de en yüksek üçüncü modelde 0.91 olarak çıkmıştır.* \n",
    "\n",
    "\n",
    "- **F1 Score -** Olumlu tahminlerin yüzde kaçı doğruydu? Precision ve Sensitivity değerlerinin harmonik ortalamasını göstermektedir. Basit bir ortalama yerine harmonik ortalama olmasının sebebi ise uç durumları da gözardı etmememiz gerektiğidir. Eğer basit bir ortalama hesaplaması olsaydı Precision değeri 1 ve Recall değeri 0 olan bir modelin F1 Score’u 0.5 olarak gelecektir ve bu bizi yanıltacaktır. Accuracy yerine F1 Score değerinin kullanılmasının en temel sebebi eşit dağılmayan veri kümelerinde hatalı bir model seçimi yapmamaktır. Ayrıca sadece False Negative ya da False Positive değil tüm hata maliyetlerini de içerecek bir ölçme metriğine ihtiyaç duyulduğu içinde F1 Score bizim için çok önemlidir.\n",
    "\n",
    "    F1 Score = 2*(Recall * Precision) / (Recall + Precision)\n",
    "    \n",
    "    *F1 Score da en yüksek üçüncü modelde 0.86 olarak çıkmıştır.* \n",
    "    \n",
    "    \n",
    "- **Support -** Belirtilen veri kümesindeki sınıfın gerçek oluşumlarının sayısıdır. Training verilerindeki dengesiz support, sınıflandırıcının rapor edilen puanlarındaki yapısal zayıflıkları gösterebilir ve tabakalı örnekleme veya yeniden dengeleme ihtiyacını gösterebilir. Support, modeller arasında değişmez, bunun yerine değerlendirme sürecini teşhis eder.\n",
    "\n",
    "    *Support birinci sınıfta 162, ikinci sınıfta 292 ve üçüncü sınıfta 656 çıkmıştır. Bu sonuca göre test setinde birinci sınıftan 162, ikinci sınıftan 292 ve üçüncü sınıftan ise 656 nesne bulunur.* \n",
    "    \n",
    "    **Sonuç olarak modelin %77 oranında doğruluk gösterdiği dikkate alınarak model performansının zayıf olduğu gözükmektedir. Bunun nedenlerinden biri, verilerin dengesizliği olabilir, yani üçüncü sınıfın birçok nesnesi ancak birinci ve ikinci sınıfın birkaç örneği vardır.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2- Random Forest Classifier**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest, adından da anlaşılacağı gibi, bir topluluk olarak çalışan çok sayıda bireysel karar ağacından oluşur. Random Forest'daki her bir ağaç bir sınıf tahmini yapar ve en çok oyu alan sınıf modelimizin tahmini olur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tahminde Bulunan Random Forest Modelinin Görselleştirilmesi*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/1052/1*VHDtVaDPNepRglIAv72BFg.jpeg\" width=\"300\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import Image, display\n",
    "display(Image(url='https://miro.medium.com/max/1052/1*VHDtVaDPNepRglIAv72BFg.jpeg', width=300, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest' ın ardındaki temel kavram basit ama güçlü bir kavramdır - kalabalıkların bilgeliği. Veri biliminde random forest modelinin bu kadar iyi çalışmasının nedeni şudur:\n",
    "\n",
    "- Bir komite olarak çalışan çok sayıda göreceli olarak ilişkisiz model (ağaçlar), bireysel kurucu modellerin herhangi birinden daha iyi performans gösterecektir. \n",
    "\n",
    "Modeller arasındaki düşük korelasyon anahtardır. Tıpkı düşük korelasyonlu yatırımların (hisse senetleri ve tahviller gibi) parçalarının toplamından daha büyük bir portföy oluşturmak için bir araya gelmesi gibi, ilişkisiz modeller de bireysel tahminlerin herhangi birinden daha doğru olan toplu tahminler üretebilir. Bu harika etkinin nedeni, ağaçların birbirlerini bireysel hatalarından korumalarıdır (sürekli aynı yönde hata yapmadıkları sürece). Bazı ağaçlar yanlış olabilirken, diğer birçok ağaç doğru olacaktır, böylece bir grup olarak ağaçlar doğru yönde hareket edebilir. Bu nedenle, rastgele ormanın iyi performans göstermesi için ön koşullar şunlardır: \n",
    "\n",
    "**1 -** Bu özellikler kullanılarak oluşturulan modellerin rastgele tahminden daha iyi sonuç vermesi için özelliklerimizde bazı gerçek sinyaller olması gerekir.\n",
    "\n",
    "**2 -** Bireysel ağaçlar tarafından yapılan tahminlerin (ve dolayısıyla hataların) birbirleriyle düşük korelasyona sahip olması gerekir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest'ın Avantaj ve Dezavantajları**\n",
    "\n",
    "-**Avantajlar** \n",
    "\n",
    "    Güçlü ve son derece hassas\n",
    "    \n",
    "    Normalleştirmeye gerek yok\n",
    "\n",
    "    Aynı anda birkaç özelliği işleyebilir\n",
    "\n",
    "    Ağaçları paralel yollarla çalıştırır \n",
    "\n",
    "-**Dezavantajlar**\n",
    "\n",
    "    Bazen belirli özelliklere önyargılıdırlar.\n",
    "    \n",
    "    Yavaş\n",
    "\n",
    "    Doğrusal yöntemler için kullanılamaz\n",
    "    \n",
    "    Yüksek boyutlu veriler için çok iyi bir yöntem değil "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi Random Forest modeli RandomForestClassifier() fonksiyonu ile tanımlayıp eğiteceğiz. Ve ardından training setleri fit edeceğiz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rmfr = RandomForestClassifier()\n",
    "rmfr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions**\n",
    "\n",
    "Test setini tahmin etmek için oluşturduğumuz rmfr modelinde predict metodunu kullanacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predrmfr = rmfr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi bu tahminleri ve y_test'i kullanarak bir confusion matrisi ve sınıflandırma raporu oluşturacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest için Confusion Matrix :\n",
      "[[ 31  34  97]\n",
      " [  1 109 182]\n",
      " [  1  19 636]]\n",
      "Score: 69.91\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.19      0.32       162\n",
      "           3       0.67      0.37      0.48       292\n",
      "           5       0.70      0.97      0.81       656\n",
      "\n",
      "    accuracy                           0.70      1110\n",
      "   macro avg       0.77      0.51      0.54      1110\n",
      "weighted avg       0.72      0.70      0.65      1110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest için Confusion Matrix :\")\n",
    "print(confusion_matrix(y_test,predrmfr))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predrmfr)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predrmfr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   *Accuracy 0.70 çıkmıştır. Modelin doğruluğu Multinomial Naive Bayes 'e göre bir miktar düşmüştür. Score ise 69.91 olmuştur.* \n",
    "\n",
    "   *Precision değeri en yüksek birinci sınıfta 0.94 olarak çıkmıştır.*\n",
    "\n",
    "   *Sensitivity değeri en yüksek üçüncü sınıfta 0.97 olarak çıkmıştır.*\n",
    "\n",
    "   *F1 Score en yüksek üçüncü sınıfta 0.81 olarak çıkmıştır.* \n",
    "   \n",
    "   *Support birinci sınıfta 162, ikinci sınıfta 292 ve üçüncü sınıfta 656 çıkmıştır. Bu sonuca göre test setinde birinci sınıftan 162, ikinci sınıftan 292 ve üçüncü sınıftan ise 656 nesne bulunur.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3- Decision Tree** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree (Karar ağacı) yöntemi hem classification (Sınıflandırma) hem de regression (regresyon) problemlerinde kullanılan makine öğrenmesinin en popüler algoritmalarından biridir. Aynı zamanda veri madenciliği alanındada sıkça kullanılır. Karar ağaçları genellikle insan seviyesinde düşünülebilecek düzeydedir, böylece verileri anlamak ve bazı iyi yorumlar yapmak ve görselleştirmek oldukça zahmetsizdir.\n",
    "\n",
    "Karar ağacı recursively (yenilemeli) bir işlemdir, adından da anlaşılacağı üzere bir ağaç yapısı kullanılır. Tek bir düğüm ile başlar ve yeni sonuçlara dallanarak bir ağaç yapısı oluşturulur. Algoritma çalıştığında girilen değer düğümlere bakılarak belli bir yolda ilerler ve bir sonuç verir.\n",
    "\n",
    "3 tane düğüm çeşidi vardır.\n",
    "\n",
    "**Chance Node (Şans Düğümü):** Daire ile gösterilir. Birden çok olası yol belirtir.\n",
    "\n",
    "**Decision Node (Karar Düğümü):** Dikdörtgen ile gösterilir. Bir karar verileceğini belirtir.\n",
    "\n",
    "**End Node (Uç Düğümü):** Üçgen ile gösterilir. Bir sonuç belirtir. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Karar Ağacının Avantaj ve Dezavantajları**\n",
    "\n",
    "- **Avantajlar**\n",
    "\n",
    "    Kolay\n",
    "    \n",
    "    Şeffaf süreç\n",
    "    \n",
    "    Hem sayısal hem de kategorik verilere işlenebilir\n",
    "\n",
    "    Veriler ne kadar büyük olursa, sonuç o kadar iyi olur\n",
    "    \n",
    "    Hızlı\n",
    "    \n",
    "\n",
    "- **Dezavantajlar**\n",
    "\n",
    "    Overfitting olabilir. \n",
    "    \n",
    "    Pruning(budama) işlemi büyük\n",
    "\n",
    "    Optimizasyon garantisi yok\n",
    "\n",
    "    Karmaşık hesaplamalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree ve Random Forest arasındaki farklar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/5752/1*5dq_1hnqkboZTcKFfwbO9A.png\" width=\"900\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import Image, display\n",
    "display(Image(url='https://miro.medium.com/max/5752/1*5dq_1hnqkboZTcKFfwbO9A.png', width=900, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karar ağaçları, random forest'a kıyasla çok kolaydır. Bir karar ağacı bazı kararları birleştirir, oysa random forest birkaç karar ağacını birleştirir. Bu nedenle, uzun ama yavaş bir süreçtir.\n",
    "\n",
    "Oysa bir karar ağacı hızlıdır ve özellikle doğrusal olan büyük veri kümelerinde kolayca çalışır. Random forest modeli sıkı bir eğitim gerektirir. Bir proje ortaya koymaya çalışırken birden fazla modele ihtiyacınız olabilir. Böylece, çok sayıda random forest, daha fazla zaman demektir.\n",
    "\n",
    "**Sonuç olarak gereksinimlerinize bağlıdır. Bir model üzerinde çalışmak için daha az zamanınız varsa, bir karar ağacı seçmek zorundasınız. Bununla birlikte, istikrarlı ve güvenilir tahminler istiyorsanız random forest daha iyi bir seçim olacaktır.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi Random Forest modeli, DecisionTreeClassifier() fonksiyonu ile tanımlayıp eğiteceğiz. Ve ardından training setleri fit edeceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions**\n",
    "\n",
    "Test setini tahmin etmek için oluşturduğumuz dt modelinde predict metodunu kullanacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "preddt = dt.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi bu tahminleri ve y_test'i kullanarak bir confusion matrisi ve sınıflandırma raporu oluşturacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree için Confusion Matrix:\n",
      "[[ 59  49  54]\n",
      " [ 37 140 115]\n",
      " [ 37  98 521]]\n",
      "Score: 64.86\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.36      0.40       162\n",
      "           3       0.49      0.48      0.48       292\n",
      "           5       0.76      0.79      0.77       656\n",
      "\n",
      "    accuracy                           0.65      1110\n",
      "   macro avg       0.56      0.55      0.55      1110\n",
      "weighted avg       0.64      0.65      0.64      1110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree için Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,preddt))\n",
    "print(\"Score:\",round(accuracy_score(y_test,preddt)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,preddt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   *Accuracy değeri oldukça düşerek 0.65 çıkmıştır. Modelin doğruluğu Multinomial Naive Bayes ve Random Forest 'e göre oldukça düşmüştür. Score değeri ise 64.96 'a düşmüştür.* \n",
    "\n",
    "   *Precision değeri en yüksek üçüncü sınıfta 0.76 olarak çıkmıştır.*\n",
    "\n",
    "   *Sensitivity değeri en yüksek üçüncü sınıfta 0.79 olarak çıkmıştır.*\n",
    "\n",
    "   *F1 Score en yüksek üçüncü sınıfta 0.77 olarak çıkmıştır.* \n",
    "   \n",
    "   *Support birinci sınıfta 162, ikinci sınıfta 292 ve üçüncü sınıfta 656 çıkmıştır. Bu sonuca göre test setinde birinci sınıftan 162, ikinci sınıftan 292 ve üçüncü sınıftan ise 656 nesne bulunur.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4- Support Vector Machines**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines, belirli bir gruba (veya kategoriye) ait vektörler ile ona ait olmayan vektörler arasındaki en iyi karar sınırını belirleyen bir algoritmadır.\n",
    "\n",
    "Her türlü veriyi kodlayan her türlü vektöre uygulanabilir. Bu, SVM metin sınıflandırmasının gücünden yararlanmak için metinlerin vektörlere dönüştürülmesi gerektiği anlamına gelir.\n",
    "\n",
    "Vektörler, bir uzayda bir dizi koordinatı temsil eden (bazen çok büyük) sayı listeleridir.\n",
    "\n",
    "Böylece, uzayı *iki alt uzaya* bölen en iyi “çizginin” (veya en iyi hiper düzlemin) nereye çizileceğine SVM karar verir: biri *verilen kategoriye ait vektörler* için, diğeri ise *kendisine ait olmayan vektörler için.*\n",
    "\n",
    "Böylece metinlerimizden mümkün olduğu kadar çok bilgiyi kodlayan vektör temsillerini bulabilirsek, SVM algoritmasını metin sınıflandırma problemlerine uygulayabilir ve çok iyi sonuçlar elde edebiliriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Örneğin, aşağıdaki grafikteki mavi daireler, bir SaaS (hizmet olarak yazılım, kullanıcıların bulut tabanlı uygulamalara İnternet üzerinden bağlanmasını ve bunları İnternet üzerinden kullanmasını sağlar. E-posta, takvim ve ofis araçları (örn. Microsoft Office 365) bu uygulamalara örnek olarak gösterilebilir) ürününün Fiyatlandırmasından bahseden eğitim metinlerinin temsilidir ve kırmızı üçgenler, bundan bahsetmeyen eğitim metinlerinin temsilleridir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://d33wubrfki0l68.cloudfront.net/6735c4ce2eaafc5e93ba22106351bba31f3ef83a/c6c7b/static/fd30f2599d2ae6afcedbe92699414a32/40f84/svm-representations-training-text.png\" width=\"600\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='https://d33wubrfki0l68.cloudfront.net/6735c4ce2eaafc5e93ba22106351bba31f3ef83a/c6c7b/static/fd30f2599d2ae6afcedbe92699414a32/40f84/svm-representations-training-text.png', width=600, unconfined=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "En iyi karar sınırı şöyle görünür: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://d33wubrfki0l68.cloudfront.net/e83782e076a5aeb995f2b56746b74be3bdb37252/99231/static/e7ec71eb361bf75bd69d70124a62fe75/40f84/svm-best_hyperplane.png\" width=\"600\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='https://d33wubrfki0l68.cloudfront.net/e83782e076a5aeb995f2b56746b74be3bdb37252/99231/static/e7ec71eb361bf75bd69d70124a62fe75/40f84/svm-best_hyperplane.png', width=600, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sonuç olarak**\n",
    "\n",
    "Algoritma, analiz etmek istediğiniz kategori için karar sınırını belirlediğine göre, yalnızca sınıflandırmak istediğiniz tüm metinlerin temsillerini elde etmeniz ve bu temsillerin sınırın hangi tarafına düştüğünü kontrol etmeniz yeterlidir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*İlgilendiğimiz veri olan Yelp 'e geri dönersek,* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines modeli, SVC fonksiyonu ile tanımlayıp eğiteceğiz. Ve ardından training setleri fit edeceğiz. \n",
    "\n",
    "random_state parametresi, verilerin train ve test endekslerine bölünmesine karar verecek olan dahili rasgele sayı üretecini başlatmak için kullanılır. Random_state'i sabit bir değere ayarlamak, kodu her çalıştırdığınızda aynı rastgele sayı dizisinin oluşturulmasını garanti eder. R 'da bulunan set.seed fonksiyonunun benzeridir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=101)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(random_state=101)\n",
    "svm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions**\n",
    "\n",
    "Test setini tahmin etmek için oluşturduğumuz svm modelinde predict metodunu kullanacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsvm = svm.predict(x_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi bu tahminleri ve y_test'i kullanarak bir confusion matrisi ve sınıflandırma raporu oluşturacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines için Confusion Matrix:\n",
      "[[ 31  23 108]\n",
      " [  5 122 165]\n",
      " [  1  19 636]]\n",
      "Score: 71.08\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.19      0.31       162\n",
      "           3       0.74      0.42      0.54       292\n",
      "           5       0.70      0.97      0.81       656\n",
      "\n",
      "    accuracy                           0.71      1110\n",
      "   macro avg       0.76      0.53      0.55      1110\n",
      "weighted avg       0.73      0.71      0.67      1110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Support Vector Machines için Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,predsvm))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predsvm)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predsvm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   *Accuracy değeri Random Forest 'e epey (0.70) yakın, 0.71 çıkmıştır. Modelin doğruluğu Random Forest 'e oldukça yakındır. Score ise 71.08 çıkmıştır* \n",
    "\n",
    "   *Precision değeri en yüksek birinci sınıfta 0.84 olarak çıkmıştır.*\n",
    "\n",
    "   *Sensitivity değeri en yüksek üçüncü sınıfta 0.97 olarak çıkmıştır.*\n",
    "\n",
    "   *F1 Score en yüksek üçüncü sınıfta 0.81 olarak çıkmıştır.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **5- Gradient Boosting Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier (Gradyan artırma sınıflandırıcıları), güçlü bir tahmine dayalı model oluşturmak için birçok zayıf öğrenme modelini bir araya getiren bir grup makine öğrenimi algoritmasıdır. Karar ağaçları genellikle gradyan artırma yapılırken kullanılır. Gradyan artırma modelleri, karmaşık veri kümelerini sınıflandırmadaki etkinlikleri nedeniyle popüler hale geliyor ve son zamanlarda birçok Kaggle veri bilimi yarışmasını kazanmak için kullanılıyor. \n",
    "\n",
    "Python makine öğrenimi kitaplığı Scikit-Learn, XGBoost dahil olmak üzere gradyan artırma sınıflandırıcılarının farklı uygulamalarını destekler. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting’in Arkasındaki Sezgi**\n",
    "\n",
    "Gradyan artırmanın ardındaki mantık basittir (matematiksel notasyon kullanmadan sezgisel olarak anlaşılabilir.) \n",
    "\n",
    "Doğrusal regresyonun temel bir varsayımı, artıklarının toplamının 0 olmasıdır, yani artıkların sıfır etrafında rastgele yayılması gerekir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://devhunteryz.files.wordpress.com/2018/07/9cb5a-1mbstjwvk-ylvpvgyjw-1da.png?w=840\" width=\"800\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(Image(url='https://devhunteryz.files.wordpress.com/2018/07/9cb5a-1mbstjwvk-ylvpvgyjw-1da.png?w=840', width=800, unconfined=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi bu kalıntıları, tahmin modelimizin yaptığı hatalar olarak düşünürsek, her ne kadar, ağaç temelli modeller (buradaki gradyanımızı geliştirmek için temel modeller olarak karar ağacını düşünmek) bu varsayımlara dayanmıyor olsa da, bu varsayım hakkında mantıklı düşünürsek, eğer kalıntı kalıbı görebiliyorsak; 0 civarında, bu modeli bir modele uyacak şekilde kullanabiliriz. \n",
    "\n",
    "Bu nedenle, gradyan artırma algoritmasının ardındaki sezgi, artıklardaki örüntüleri tekrar tekrar kullanmak ve zayıf tahminlerle bir modeli güçlendirmek ve daha iyi hale getirmektir. Kalıntıların modellenebilecek herhangi bir örüntü olmadığı bir aşamaya ulaştığımızda, modelleme artıklarını durdurabiliriz (aksi takdirde overfitting'e yol açabilir). Algoritmik olarak, kayıp fonksiyonunu en aza indiririz, böylece test kaybı en düşük seviyeye ulaşır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Özetle;**\n",
    "\n",
    "- İlk önce veriler basit modellerle modellenir ve hatalar için veriler analiz edilir\n",
    "\n",
    "\n",
    "- Bu hatalar, basit bir modelle sığması zor veri noktalarını gösterir \n",
    "\n",
    "\n",
    "- Daha sonra modeller için, özellikle onları doğru bir şekilde elde etmek için veriye sığması zor olanlara odaklanırız\n",
    "\n",
    "\n",
    "- Sonunda, tüm tahminleri her bir belirleyiciye biraz ağırlık vererek birleştiririz \n",
    "\n",
    "Aynı mantığın daha teknik bir alıntısı, ‘Muhtemelen Yaklaşık Doğru: Karmaşık Bir Dünyada Öğrenme ve İyileştirme için Doğanın Algoritmaları’ kitabında yazılmıştır: (Probably Approximately Correct: Nature's Algorithms for Learning and Prospering in a Complex World, Leslie Valiant)\n",
    "\n",
    "“Fikir, zayıf öğrenme yöntemini birkaç kez hipotezler elde etmek için kullanmaktır; her biri, öncekilerin zor ve yanlış sınıflandırılmış olduğu örneklere odaklanmıştır. Ancak, bunun nasıl yapılabileceği hiç de belli değil.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-76358281b4ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#Boosting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mgbi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m999999\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mgbi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mpredgbi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgbi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Confusion Matrix for Gradient Boosting Classifier:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\"\"\"# parametre değerlendirmesi\n",
    "gbe = GradientBoostingClassifier(random_state=0)\n",
    "parameters = {\n",
    "     'learning_rate': [0.05, 0.1, 0.5],\n",
    "    'max_features': [0.5, 1],\n",
    "    'max_depth': [3, 4, 5]}\n",
    "gridsearch=GridSearchCV(gbe,parameters,cv=100,scoring='roc_auc')\n",
    "gridsearch.fit(x,y)\n",
    "print(gridsearch.best_params_)\n",
    "print(gridsearch.best_score_)\"\"\"\n",
    "#Boosting\n",
    "gbi = GradientBoostingClassifier(learning_rate=0.1,max_depth=5,max_features=0.5,random_state=999999)\n",
    "gbi.fit(x_train,y_train)\n",
    "predgbi = gbi.predict(x_test)\n",
    "print(\"Confusion Matrix for Gradient Boosting Classifier:\")\n",
    "print(confusion_matrix(y_test,predgbi))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predgbi)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predgbi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6- K - Nearest Neighbor Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K - Nearest Neighbor Classifier (K - en yakın komşuluk) (KNN) algoritması, uygulaması kolay gözetimli öğrenme algoritmalarındandır. Hem sınıflandırma hem de regresyon problemlerinin çözümünde kullanılıyor olmakla birlikte, endüstride çoğunlukla sınıflandırma problemlerinin çözümünde kullanılmaktadır.\n",
    "\n",
    "KNN algoritmaları, 1967 yılında T. M. Cover ve P. E. Hart tarafından önerilmiştir. Algoritma, sınıfları belli olan bir örnek kümesindeki verilerden yararlanılarak kullanılmaktadır. Örnek veri setine katılacak olan yeni verinin, mevcut verilere göre uzaklığı hesaplanıp, k sayıda yakın komşuluğuna bakılır. Uzaklık hesapları için genelde 3 tip uzaklık fonksiyonu kullanılmaktadır:\n",
    "\n",
    "“Euclidean” Uzaklık\n",
    "\n",
    "“Manhattan” Uzaklık\n",
    "\n",
    "“Minkowski” Uzaklığı’dır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/357/1*IxvVTCXAUsDTsXop6kNJjA.png\" width=\"800\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='https://miro.medium.com/max/357/1*IxvVTCXAUsDTsXop6kNJjA.png', width=800, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN; eski, basit ve gürültülü eğitim verilerine karşı dirençli olması sebebiyle en popüler makine öğrenme algoritmalarından biridir. Fakat bunun yanında dezavantajı da mevcuttur. Örneğin, uzaklık hesabı yaparken bütün durumları sakladığından, büyük veriler için kullanıldığında çok sayıda bellek alanına gereksinim duymaktadır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN algoritmasının adımları:**\n",
    "\n",
    "İlk olarak k parametresi belirlenir. Bu parametre verilen bir noktaya en yakın komşuların sayısıdır. Örneğin: k=2 olsun. Bu durumda en yakın 2 komşuya göre sınıflandırma yapılacaktır.\n",
    "\n",
    "Örnek veri setine katılacak olan yeni verinin, ilgili uzaklık fonksiyonları yardımıyla mevcut verilere göre uzaklığı tek tek hesaplanır. \n",
    "\n",
    "İlgili uzaklılardan en yakın k komşu ele alınır. Öznitelik değerlerine göre k komşu veya komşuların sınıfına atanır. Seçilen sınıf, tahmin edilmesi beklenen gözlem değerinin sınıfı olarak kabul edilir. Yani yeni veri etiketlenmiş (label) olur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu algoritmayı anlamak için basit bir vakayı ele alalım. Aşağıda kırmızı dairelerin (RC) ve yeşil karelerin (GS) dağılımı verilmiştir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.analyticsvidhya.com/wp-content/uploads/2014/10/scenario1.png\" width=\"800\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='https://www.analyticsvidhya.com/wp-content/uploads/2014/10/scenario1.png', width=800, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mavi yıldızın (BS) sınıfını öğrenmek niyetindesiniz. BS, RC veya GS olabilir ve başka bir şey olmayabilir. “K” KNN algoritmasıdır ve oyu almak istediğimiz en yakın komşumuzdur. Diyelim ki K = 3. Bu nedenle, şimdi düzlemde sadece üç veri noktasını içine alacak kadar büyük, merkezi BS olan bir daire yapacağız. Daha fazla ayrıntı için aşağıdaki şemaya bakın:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.analyticsvidhya.com/wp-content/uploads/2014/10/scenario2.png\" width=\"800\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='https://www.analyticsvidhya.com/wp-content/uploads/2014/10/scenario2.png', width=800, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BS'ye en yakın üç noktanın tümü RC'dir. Bu nedenle, iyi bir güven düzeyi ile BS'nin RC sınıfına ait olması gerektiğini söyleyebiliriz. Burada, en yakın komşudan gelen üç oy da RC'ye gittiği için seçim çok açık hale geldi. Bu algoritmada K parametresinin seçimi çok önemlidir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K faktörünü nasıl seçeriz?**\n",
    "\n",
    "Önce K algoritmasında tam olarak neyi etkilediğini anlamaya çalışalım. Son örneğe bakarsak, 6 eğitim gözleminin tamamının sabit kaldığı göz önüne alındığında, verilen bir K değeri ile her sınıfın sınırlarını yapabiliriz. Bu sınırlar, RC'yi GS'den ayıracaktır. Aynı şekilde “K” değerinin sınıf sınırları üzerindeki etkisini görmeye çalışalım. Aşağıdakiler, farklı K değerlerine sahip iki sınıfı ayıran farklı sınırlardır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.analyticsvidhya.com/wp-content/uploads/2014/10/K-judgement.png\" width=\"800\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='https://www.analyticsvidhya.com/wp-content/uploads/2014/10/K-judgement.png', width=800, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dikkatlice incelersek, artan K değeri ile sınırın daha düzgün hale geldiğini görebiliriz. K sonsuza kadar arttıkça, toplam çoğunluğa bağlı olarak sonunda tamamen mavi veya tamamen kırmızı olur. Training hata oranı ve doğrulama hata oranı, farklı K değerlerine erişmek için ihtiyacımız olan iki parametredir. Değişen bir K değerine sahip training hata oranı eğrisi aşağıdadır:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.analyticsvidhya.com/wp-content/uploads/2014/10/training-error.png\" width=\"800\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='https://www.analyticsvidhya.com/wp-content/uploads/2014/10/training-error.png', width=800, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gördüğünüz gibi, training örneği için K=1'deki hata oranı her zaman sıfırdır. Bunun nedeni, herhangi bir training veri noktasına en yakın noktanın kendisi olmasıdır. Bu nedenle, tahmin her zaman K=1 ile doğrudur. Doğrulama hatası eğrisi benzer olsaydı, K seçimimiz 1 olurdu. Değişen K değerine sahip doğrulama hatası eğrisi aşağıdadır:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.analyticsvidhya.com/wp-content/uploads/2014/10/training-error_11.png\" width=\"800\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='https://www.analyticsvidhya.com/wp-content/uploads/2014/10/training-error_11.png', width=800, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu hikayeyi daha net hale getiriyor. K=1'de sınırlara fazla uyuyorduk. Bu nedenle, hata oranı başlangıçta azalır ve bir minimuma ulaşır. Minimum noktasından sonra, artan K ile artar. En uygun K değerini elde etmek için training ve doğrulamayı ilk veri kümesinden ayırabilirsiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python 'da KNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sklearn.neighbors.KNeighborsClassifier fonksiyonu**\n",
    "\n",
    "class sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None, **kwargs)  \n",
    "\n",
    "**parametreler** \n",
    "\n",
    "- n_neighbors : Kneighbors sorguları için kullanılacak komşu sayısı, default=5 olarak alır. \n",
    "\n",
    "\n",
    "- weight: tahminde kullanılan ağırlık fonksiyonudur. {‘uniform’, ‘distance’} ya da callable olabilir. fonksiyon default olarak ’uniform’ alır. \n",
    "\n",
    "    *uniform: tek tip ağırlıklar.*\n",
    "    \n",
    "    *distance: mesafelerinin tersi ile ağırlık noktaları. bu durumda, bir sorgu noktasının daha yakın komşuları, uzaktaki komşulardan daha büyük bir etkiye sahip olacaktır.*\n",
    "    \n",
    "    *callable: bir dizi uzaklığı kabul eden ve ağırlıkları içeren aynı şekle sahip bir dizi döndüren kullanıcı tanımlı bir işlev.* \n",
    "    \n",
    "\n",
    "- algorithm: en yakın komşuları hesaplamak için kullanılır. {'auto', 'ball_tree', 'kd_tree', 'brute'} olabilir. default olarak 'auto' alır.\n",
    "\n",
    "    *ball_tree: BallTree için kullanılır.*\n",
    "    \n",
    "    *kd_tree: KDTree için kullanılır.* \n",
    "    \n",
    "    *brute: brute force araması için kullanılır.* \n",
    "    \n",
    "    *auto: fit yöntemine iletilen değerlere göre en uygun algoritmaya karar vermeye çalışır.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi K Nearest Neighbour modeli oluşturup KNeighborsClassifier fonksiyonu ile tanımlayıp eğiteceğiz. Ve ardından training setleri fit edeceğiz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=10)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K Nearest Neighbour Algorithm \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi bu tahminleri ve y_test'i kullanarak bir confusion matrisi ve sınıflandırma raporu oluşturacağız. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Neighbors Classifier için Confusion Matrix:\n",
      "[[ 12  10 140]\n",
      " [  3  33 256]\n",
      " [  8  12 636]]\n",
      "Score:  61.35\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.07      0.13       162\n",
      "           3       0.60      0.11      0.19       292\n",
      "           5       0.62      0.97      0.75       656\n",
      "\n",
      "    accuracy                           0.61      1110\n",
      "   macro avg       0.58      0.39      0.36      1110\n",
      "weighted avg       0.60      0.61      0.51      1110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predknn = knn.predict(x_test)\n",
    "print(\"K Neighbors Classifier için Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,predknn))\n",
    "print(\"Score: \",round(accuracy_score(y_test,predknn)*100,2))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,predknn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin tahmin performansı 0.61 , Score ise 61.35 çıkmıştır. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7- XGBoost Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost, gradyan artırma çerçevesi kullanan karar ağacı tabanlı bir topluluk Makine Öğrenimi algoritmasıdır. Yapılandırılmamış verileri (görüntüler, metin vb.) içeren tahmin problemlerinde yapay sinir ağları, diğer tüm algoritma veya çerçevelerden daha iyi performans gösterme eğilimindedir. Bununla birlikte, küçük ve orta ölçekli yapılandırılmış/tablolu veriler söz konusu olduğunda, karar ağacı tabanlı algoritmalar şu anda sınıfının en iyisi olarak kabul edilmektedir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost algoritması, Washington Üniversitesi'nde bir araştırma projesi olarak geliştirildi. Tianqi Chen ve Carlos Guestrin, 2016 yılında SIGKDD Konferansında bildirilerini sundular. Bu algoritma, piyasaya sürülmesinden bu yana, yalnızca sayısız Kaggle yarışmasını kazanmakla kalmayıp, aynı zamanda çeşitli son teknoloji endüstri uygulamaları için kaputun altındaki itici güç olduğu için de itibar kazanmıştır.\n",
    "\n",
    "Algoritma kendisini aşağıdaki şekillerde farklılaştırır:\n",
    "\n",
    "- **Geniş bir uygulama yelpazesi:** Regresyon, sınıflandırma, sıralama ve kullanıcı tanımlı tahmin problemlerini çözmek için kullanılabilir.\n",
    "\n",
    "- **Taşınabilirlik:** Windows, Linux ve OS X üzerinde sorunsuz çalışır.\n",
    "\n",
    "- **Diller:** C++, Python, R, Java, Scala ve Julia dahil tüm önemli programlama dillerini destekler.\n",
    "\n",
    "- **Bulut Entegrasyonu:** AWS, Azure ve Yarn kümelerini destekler ve Flink, Spark ve diğer ekosistemlerle iyi çalışır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost için bir sezgi nasıl oluşturulur?**\n",
    "\n",
    "Karar ağaçları, en basit biçimleriyle, görselleştirilmesi kolay ve oldukça yorumlanabilir algoritmalardır, ancak yeni nesil ağaç tabanlı algoritmalar için sezgi oluşturmak biraz zor olabilir. Ağaç tabanlı algoritmaların gelişimini daha iyi anlamak için basit bir benzetme yapalım. \n",
    "\n",
    "Mükemmel niteliklere sahip birkaç adayla röportaj yapan bir işe alım yöneticisi olduğunuzu hayal edin. Ağaç tabanlı algoritmaların evriminin her adımı, görüşme sürecinin bir versiyonu olarak görülebilir. \n",
    "\n",
    "- **Decision Tree:** Her işe alım yöneticisinin eğitim düzeyi, deneyim yılı sayısı, mülakat performansı gibi bir takım kriterleri vardır. Karar ağacı, işe alım yöneticisinin adaylarla kendi kriterlerine göre görüşme yapmasına benzer.\n",
    "\n",
    "\n",
    "- **Bagging:** Şimdi her görüşmecinin oy kullandığı bir görüşme panelinin var olduğunu hayal edin. Bagging veya bootstrap, demokratik bir oylama süreci aracılığıyla nihai karar için tüm görüşmecilerden gelen girdilerin birleştirilmesini içerir.\n",
    "\n",
    "\n",
    "- **Random Forest:** Anahtar farkı olan, yalnızca özelliklerin bir alt kümesinin rastgele seçildiği bagging tabanlı bir algoritmadır. Başka bir deyişle, her görüşmeci görüşülen kişiyi yalnızca rastgele seçilmiş belirli nitelikler üzerinde test edecektir (örneğin, programlama becerilerini test etmek için teknik bir görüşme ve teknik olmayan becerileri değerlendirmek için davranışsal bir görüşme).\n",
    "\n",
    "\n",
    "- **Boosting:** Bu, her görüşmecinin önceki görüşmeciden gelen geri bildirime dayalı olarak değerlendirme kriterlerini değiştirdiği alternatif bir yaklaşımdır. Bu, daha dinamik bir değerlendirme süreci uygulayarak görüşme sürecinin verimliliğini 'artırır'.\n",
    "\n",
    "\n",
    "- **Gradient Boosting:** Gradient iniş algoritması ile hataların en aza indirildiği özel bir boosting durumu, örn. strateji danışmanlığı firmaları, daha az nitelikli adayları ayıklamak için vaka görüşmelerini kullanarak avantaj sağlıyor.\n",
    "\n",
    "\n",
    "- **XGBoost:** XGBoost'u 'steroidler' üzerinde gradyan artırma olarak düşünün (bir nedenden dolayı 'Aşırı Gradyan Artırma' olarak adlandırılır.) En kısa sürede daha az bilgi işlem kaynağı kullanarak üstün sonuçlar elde etmek için yazılım ve donanım optimizasyon tekniklerinin mükemmel bir birleşimidir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sistem Optimizasyonu:**\n",
    "\n",
    "- **Paralelleştirme:** XGBoost, paralelleştirilmiş uygulama kullanarak sıralı ağaç oluşturma sürecine yaklaşır. Bu, temel öğrenenler oluşturmak için kullanılan döngülerin değiştirilebilir doğası nedeniyle mümkündür; bir ağacın yaprak düğümlerini sıralayan dış döngü ve özellikleri hesaplayan ikinci iç döngü. Döngülerin bu iç içe yerleştirilmesi paralelleştirmeyi sınırlar çünkü iç döngü tamamlanmadan (ikisinden daha fazla hesaplama gerektirir), dış döngü başlatılamaz. Bu nedenle, çalışma süresini iyileştirmek için döngülerin sırası, tüm örneklerin genel taraması yoluyla başlatma ve paralel iş parçacıkları kullanılarak sıralama kullanılarak değiştirilir. Bu anahtar, hesaplamadaki herhangi bir paralelleştirme ek yükünü dengeleyerek algoritmik performansı iyileştirir.\n",
    "\n",
    "\n",
    "- **Tree Pruning(Budama):** GBM çerçevesinde ağaç yarılması için durdurma kriteri, doğası gereği açgözlüdür ve bölünme noktasındaki negatif kayıp kriterine bağlıdır. XGBoost, önce kriter yerine belirtildiği gibi 'max_depth' parametresini kullanır ve ağaçları geriye doğru budamaya başlar. Bu \"önce derinlik\" yaklaşımı, hesaplama performansını önemli ölçüde artırır.\n",
    "\n",
    "\n",
    "- **Donanım Optimizasyonu:** Bu algoritma, donanım kaynaklarının verimli kullanılması için tasarlanmıştır. Bu, gradyan istatistiklerini depolamak için her bir iş parçacığında dahili arabellekler tahsis ederek önbellek farkındalığı ile gerçekleştirilir. \"Çekirdek dışı\" bilgi işlem gibi diğer geliştirmeler, belleğe sığmayan büyük veri çerçevelerini işlerken kullanılabilir disk alanını optimize eder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kanıtlar**\n",
    "\n",
    "Yapılan bir araştırmada 20 özellik (2 bilgilendirici ve 2 yedekli) ile 1 milyon veri noktasından rastgele bir örnek oluşturmak için Scikit-learn'in \"Make_Classification\" veri paketi kullanıldı ve Lojistik Regresyon, Random Forest, standart Gradient Boost ve XGBoost gibi çeşitli algoritmalar test edildi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/1920/1*U72CpSTnJ-XTjCisJqCqLg.jpeg\" width=\"800\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='https://miro.medium.com/max/1920/1*U72CpSTnJ-XTjCisJqCqLg.jpeg', width=800, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yukarıdaki grafikte gösterildiği gibi, XGBoost modeli, diğer algoritmalara kıyasla en iyi tahmin performansı ve işlem süresi kombinasyonuna sahiptir. Diğer birçok titiz kıyaslama çalışmaları da benzer sonuçlar vermiştir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"Şüpheye düştüğünüzde, XGBoost kullanın\" — Owen Zhang, Kaggle'da Avito Bağlam Reklamı Tıklama Tahmini yarışmasının galibi.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python 'da XGBoost Classifier**\n",
    "\n",
    "'xgboost', gradyan artırma yöntemleri altında makine öğrenimi algoritmaları sağlayan açık kaynaklı bir kitaplıktır.\n",
    "\n",
    " xgboost.XGBClassifier, sınıflandırma için scikit-learn API uyumlu bir sınıftır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-73d05c607adc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# training setleri fit edelim.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Bu tahminleri ve y_test'i kullanarak bir confusion matrisi ve sınıflandırma raporu oluşturalım.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "# XGBoost Classifier\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# XGBClassifier() fonksiyonunu tanımlayalım. \n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# training setleri fit edelim.\n",
    "\n",
    "xgb.fit(x_train,y_train)\n",
    "\n",
    "# Bu tahminleri ve y_test'i kullanarak bir confusion matrisi ve sınıflandırma raporu oluşturalım. \n",
    "\n",
    "predxgb = xgb.predict(x_test)\n",
    "print(\"XGBoost Classifier için Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test,predxgb))\n",
    "print(\"Score: \",round(accuracy_score(y_test,predxgb)*100,2))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,predxgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sırasıyla 0.76 ve 76.4 olmak üzere şu ana kadar yaptığımız çalışmalara göre en yüksek accuracy ve score değerini elde ettik. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8- Multilayer Perceptron (Çok Katmanlı Algılayıcı)** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilayer Perceptrom Model’den  önce **Perceptron Model**’den bahsetmek gerekiyor. Perceptron Model bir Yapay Sinir Ağları modelidir ve bugünkü Yapay Sinir Ağları için önemli bir temel oluşturmaktadır. Supervised (denetimli) bir training (öğrenme) algoritmasıdır. Yani ağa hem giriş hem de çıkış kümesi verili ve öğrenme beklenir. Perceptron Modeli’nde en önemli faktör eşik değeridir. Bu değer kullanılarak güzel bir sınıflandırma yapılabilmektedir. Saptanacak olan eşik değeri probleme göre belirlenebilir. Bu modelde iterasyon sayısı artırılarak öğrenme derecesi artırılabilir. Tek Katmanlı Algılayıcı’lar aşağıdaki şekilde modellenmiştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://www.nuhazginoglu.com/wp-content/uploads/2018/05/1-12.png\" width=\"500\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='http://www.nuhazginoglu.com/wp-content/uploads/2018/05/1-12.png', width=500, unconfined=True))\n",
    "\n",
    "#Şekil - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelde görülen x değerleri girişleri, w değerleri ise ağırlıkları ifade edilmektedir. BIAS değeri ise öğrenmeyi güçlendirmek için kullanılır. Ayrıca öğrenmeyi güçlendirirken yerel optimum değerler takılmayı da önler. Bu modelin algoritma adımlar şu şekildedir;\n",
    "\n",
    "**Adım 1)** Tüm ağırlıklara başlangıç değerleri atanır. Öğrenme katsayısına küçük bir değer verilir. (Örn: Bias = 0)\n",
    "\n",
    "**Adım 2)** Adım 3 ile 7 arasını belirli bir iterasyon sayısına ulaşılıncaya kadar tekrarla.\n",
    "\n",
    "**Adım 3)** Her bir girdi için Adım 4 ile 6 arasını tekrarla.\n",
    "\n",
    "**Adım 4)** Girdi değerlerini girdiden al.\n",
    "\n",
    "**Adım 5)** Perceptron’a gelen toplam sinyali hesapla. Aktivasyonu hesapla.\n",
    "\n",
    "**Adım 6)** Eğer hesaplanan değer beklen değerden farklı ise, hesaplama yanlıştır. Ağırlıkları güncelle.\n",
    "\n",
    "**Adım 7)** Döngü sonunu kontrol et.\n",
    "\n",
    "Şekil-1’de görüldüğü üzere Perceptron Model tek katmanlıdır. Bu yüzden Single Perceptron Model de denmektedir. Sadece giriş ve çıkış katmanı bulunmaktadır. Net girdi hesaplanır. Girdi eşik değerin altındaysa 0, üstündeyse 1 olarak çıkış değeri belirlenir. Çıkış beklenen değerden farklı ise ağırlık güncellemesi yapılır. Şöyle ki ; Eğer çıkış 1 bekleniyorken, 0 olarak alınmışsa ağırlıklarda artırılmaya gidilir. Tersi durumda ise ağırlıklar azaltılır. Artırım ve azaltım belirlenen delta değeri ile yapılır. Tüm eğitim seti için doğru sonuçlar bulunana kadar algoritma devam ettirilir. Her biri için doğru sonuçlar bulunduğunda öğrenme tamamlanmış sayılır. Bu modelde elde edilen çıktı fonksiyonu doğrusaldır. Perceptron Modeli ile ağa gösterilen örnekler iki sınıf arasında paylaştırılarak iki sınıfı birbirinden ayıran doğru bulunmaya çalışılır. Aşağıda örnekle gösterilmiştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://www.nuhazginoglu.com/wp-content/uploads/2018/05/1-13.png\" width=\"300\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='http://www.nuhazginoglu.com/wp-content/uploads/2018/05/1-13.png', width=300, unconfined=True))\n",
    "\n",
    "#Şekil - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://www.nuhazginoglu.com/wp-content/uploads/2018/05/1-14.png\" width=\"150\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='http://www.nuhazginoglu.com/wp-content/uploads/2018/05/1-14.png', width=150, unconfined=True))\n",
    "\n",
    "##Şekil - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DOĞRUSAL AYRILABİLİRLİK (Linear Seperability)**\n",
    "\n",
    "Bir düzlemde sadece bir hat varsa iki sınıfa ait iki boyutlu örüntülerin bir kümesi doğrusal olarak ayrılabilirdir. Şekil-2’de görülen doğru düzlemi bir hatla ikiye ayırmıştır. Verilen düzlemdeki örneklerin hepsi iki gruptan birine dahil olmuştur. Yani problem çözülebilir. Konuya örnek olarak and ve or fonksiyonları verilebilir. Bunları şekil üzerinden görelim. Yandaki şekilde veya fonksiyonu gösterilmiştir. Bilindiği üzere or fonksiyonunun 1 çıkışı vermesi için giriş değerlerinden birinin bir olması yeterli  olur. Bu durumda or fonksiyonunun çıktılarını düzlemde iki gruba ayırmak istersek yandaki şekilde bu işlemi gerçekleştirebilir. Yani or fonksiyonu doğrusal ayrılabilirdir. Or fonksiyonunu yapay sinir ağları yöntemleriyle sisteme öğretmeye çalışırsak başarılı olabiliriz. Aynı durum and fonksiyonu içinde geçerlidir. Tek farkı doğru farklı yerden geçip düzlemi ikiye ayıracaktır. Eğer bir problem doğrusal ayrılabilir ise o zaman Perceptron Öğrenimi ile örüntülerin bir kümesinden ağırlıklar elde edilebilir. Eğer problem doğrusal ayrılabilir değilse Single Perceptron Modeli ile çözüme ulaşamayız."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XOR PROBLEMi**\n",
    "\n",
    "Xor fonksiyonu doğrusal ayrılabilir değildir. Daha önce bahsettiğimiz or ve and fonksiyonunun çıktılarını düzlemde iki gruba ayırabiliyorduk. Fakat xor fonksiyonunda bunu gerçekleştiremiyoruz. Düzlemdeki çıktıları tek bir hatla ikiye bölemiyoruz.(Şekil 5) En az iki doğru gerekiyor. Xor problemi Yapay Sinir Ağları’nın “Hello World”ü olarak bilinir. Perceptronlar XOR Problemi gibi doğrusal olarak sınıflandırılamayan problemleri çözümünde başarısızdır. XOR Problemi’ni çözmek için geriye yayılımlı çok katmanlı ağlardan faydalanılabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://www.nuhazginoglu.com/wp-content/uploads/2018/05/1-15.png\" width=\"100\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='http://www.nuhazginoglu.com/wp-content/uploads/2018/05/1-15.png', width=100, unconfined=True))\n",
    "\n",
    "##Şekil - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://www.nuhazginoglu.com/wp-content/uploads/2018/05/1-16.png\" width=\"500\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='http://www.nuhazginoglu.com/wp-content/uploads/2018/05/1-16.png', width=500, unconfined=True))\n",
    "\n",
    "##Şekil - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8- Multilayer Perceptron (Çok Katmanlı Algılayıcı)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Çok Katmanlı Algılayıcılar (MLP) XOR Problemi’ni çözmek için yapılan çalışmalar sonucu ortaya çıkmıştır. Rumelhart ve arkadaşları tarafından geliştirilen bu modeli ‘Back Propogation Model’ yada hatayı ağa yaydığı için ‘Hata Yayma Modeli’ de denmektedir. Delta Öğrenme Kuralı denilen bir öğrenme metodu kullanır. MLP özellikle sınıflandırma ve genelleme yapma durumlarında etkin çalışır. Çok Katmanlı Ağ’ların yapısı aşağıdaki gibidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://www.nuhazginoglu.com/wp-content/uploads/2018/05/1.jpg\" width=\"400\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='http://www.nuhazginoglu.com/wp-content/uploads/2018/05/1.jpg', width=400, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Birçok giriş için bir nöron yeterli olmayabilir. Paralel işlem yapan birden fazla nörona ihtiyaç duyulduğunda katman kavramı devreye girer. Görüldüğü üzere Single Perceptron Model’den farklı olarak arada gizli(hidden) katman bulunmaktadır. Giriş katmanı gelen verileri alarak ara katmana gönderir. Gelen bilgiler bir sonraki katmana aktarılırlar. Ara katman sayısı en az bir olmak üzere probleme göre değişir ve ihtiyaca göre ayarlanır. Her katmanın çıkışı bir sonraki katmanın girişi olmaktadır. Böylelikle çıkışa ulaşılmaktadır. Her işlem elemanı yani nöron bir sonraki katmanda bulunan bütün nöronlara bağlıdır. Ayrıca katmandaki nöron sayısı da probleme göre belirlenir. Çıkış katmanı önceki katmanlardan gelen verileri işleyerek ağın çıkışını belirler. Sistemin çıkış sayısı çıkış katmanında bulunan eleman sayısına eşittir. Single Perceptron Modeli incelerken bahsettiğimiz nöron yapısı burada aynen geçerlidir.\n",
    "\n",
    "Modelde aktivasyon fonksiyonu olarak herhangi bir matematiksel fonksiyon kullanılabilir. Ancak Sigmoid, tang, lineer, threshold ve hard limiter fonksiyonları en çok kullanılan fonksiyonlardır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://www.nuhazginoglu.com/wp-content/uploads/2018/05/1-17.png\" width=\"500\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='http://www.nuhazginoglu.com/wp-content/uploads/2018/05/1-17.png', width=500, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Çok katmanlı ağlardaki hücreler yandaki gibidir. Aktivasyon fonksiyonu olarak yandaki modelde sigmoid fonksiyonu seçilmiştir. Çok katmanlı ağda öğrenme Delta Öğrenme Kuralı tabanlıdır. Ağın öğrenebilmesi için örnek giriş ve çıkışlardan oluşan  eğitim seti şarttır. Geri Yayılımlı Yapay Sinir Ağları’nda öğrenme işlemi bir anlamda örnek setindeki giriş değerleriyle, çıkış değerlerini eşleştiren fonksiyonu bulma işlemidir.  Sistemin öğrenme metodu genel olarak iki aşamadan oluşur. Birinci kısım ileri doğru hesaplamadır. İkinci kısım ise geri doğru hesaplamadır (back propogation).\n",
    "\n",
    "İleri doğru hesaplama aşamasında sisteme verilen girdi ara katmanlardan geçerek çıkışa ulaşır. Her işlem elemanına gelen girdiler toplanılarak net girdi hesaplanır. Bu net girdi aktivasyon fonksiyonundan geçirilerek mevcut işlem elemanının çıktısı bulunur. Ve bu çıktı değeri bir sonraki katmanda bulunan işlem elemanlarına gönderilir. Bu işlemler tekrar edilerek en son çıktı katmanından çıktılar elde edilir. En çok kullanılan aktivasyon fonksiyonu olan sigmoid fonksiyonu şekildedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://www.nuhazginoglu.com/wp-content/uploads/2018/05/1-18.png\" width=\"600\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='http://www.nuhazginoglu.com/wp-content/uploads/2018/05/1-18.png', width=600, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ağdan çıktı alınmasıyla öğrenmenin ilk aşaması bitirilmiş olur. İkinci aşama hatanın dağıtılması olacaktır. Beklenen çıktı değeri ile elde ettiğimiz birbirinden farklı ise hata vardır. Geriye doğru hesaplama aşamasında hata ağırlık değerlerine dağıtılarak her iterasyonda azaltılması beklenir. Sisteme başlangıçta random olarak verilen ağırlık değerleri, hataların ağırlıklara dağıtılmasıyla her iterasyonda güncellenmiş olur.\n",
    "\n",
    "Genelleştirilmiş Delta Öğrenme Kuralı’nın yapısı genel olarak aşağıdaki gibidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://www.nuhazginoglu.com/wp-content/uploads/2018/05/1-19.png\" width=\"600\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url='http://www.nuhazginoglu.com/wp-content/uploads/2018/05/1-19.png', width=600, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-layer Perceptron(MLP) yani Çok Katmanlı Algılayıcılar, Yapay Sinir Ağları’na olan ilgiyi hızlı bir şekilde artırmıştır. MLP ile birlikte YSA tarihinde yeni bir dönem başlamıştır. Geniş kullanım alanına sahiptir. Örnek verecek olursak; Otomotiv alanında yol izleme, rehberlik vs. gibi konularda kullanılmaktadır. Bankacılıkta kredi kartı suçu tespiti ve kredi uygulamalarında kullanılmaktadır. Uzay sanayinde uçuş simülasyonu  ve otomatik pilot uygulamalarında kullanılır. Finans sektöründe ise döviz kuru tahminlerinde kullanılır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu bilgiler ışığında Yelp verimize geri dönersek, Multi-Layer Perceptron(Çok Katmanlı Algılayıcılar) uygulamasını yapalım. \n",
    "\n",
    "**Python 'da Çok Katmanlı Algılayıcılar**\n",
    "\n",
    "Şimdi MLPClassifier modeli oluşturup MLPClassifier() fonksiyonu ile tanımlayıp eğiteceğiz. Ve ardından training setleri fit edeceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi bu tahminleri ve y_test'i kullanarak bir confusion matrisi ve sınıflandırma raporu oluşturacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Multilayer Perceptron Classifier:\n",
      "[[ 98  38  26]\n",
      " [ 26 182  84]\n",
      " [ 11  65 580]]\n",
      "Score: 77.48\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.60      0.66       162\n",
      "           3       0.64      0.62      0.63       292\n",
      "           5       0.84      0.88      0.86       656\n",
      "\n",
      "    accuracy                           0.77      1110\n",
      "   macro avg       0.74      0.70      0.72      1110\n",
      "weighted avg       0.77      0.77      0.77      1110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predmlp = mlp.predict(x_test)\n",
    "print(\"Confusion Matrix for Multilayer Perceptron Classifier:\")\n",
    "print(confusion_matrix(y_test,predmlp))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmlp)*100,2))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,predmlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy değeri 0.77 ve score ise 77.48 çıkmıştır. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yukarıdaki algoritma modellemelerinden score değerlerini şu şekilde görebiliriz: \n",
    "\n",
    "**1- Multilayer Perceptron = %77,48** \n",
    "\n",
    "**2- Multinomial Naive Bayes = %76,94** \n",
    "\n",
    "**3- XGBoost Classifier = %76,4** \n",
    "\n",
    "**4- Gradient Boosting Classifier = %73.87**\n",
    "\n",
    "**5- Support Vector Machine = %71,08**\n",
    "\n",
    "**6- Random Forest Classifier = %69,91** \n",
    "\n",
    "**7- Decision Tree = %64,96**\n",
    "\n",
    "**8- K Neighbor Classifier = %61,35** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Çok katmanlı algılayıcı sınıflandırıcı(Multilayer Perceptron) en iyi puana sahip olduğundan, rastgele bir pozitif incelemeyi, rastgele bir ortalama incelemeyi ve rastgele bir negatif incelemeyi tahmin etmek için kullanalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\n",
      "\n",
      "Do yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I've ever had.  I'm pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.\n",
      "\n",
      "While EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best \"toast\" I've ever had.\n",
      "\n",
      "Anyway, I can't wait to go back!\n",
      "Actual Rating:  5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-be405c518313>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Actual Rating: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stars'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpr_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicted Rating:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpr_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vocab' is not defined"
     ]
    }
   ],
   "source": [
    "# POZİTİF İNCELEME\n",
    "pr = data['text'][0]\n",
    "print(pr)\n",
    "print(\"Actual Rating: \",data['stars'][0])\n",
    "pr_t = vocab.transform([pr])\n",
    "print(\"Predicted Rating:\")\n",
    "mlp.predict(pr_t)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Görüldüğü gibi, actual rating ve predicted rating birbirini desteklemektedir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORTALAMA İNCELEME\n",
    "ar = data['text'][16]\n",
    "print(ar)\n",
    "print(\"Actual Rating: \",data['stars'][16])\n",
    "ar_t = vocab.transform([ar])\n",
    "print(\"Predicted Rating:\")\n",
    "mlp.predict(ar_t)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Görüldüğü gibi, actual rating ve predicted rating birbirini desteklemektedir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "lower not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-53b68179e92f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1198\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1199\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \"\"\"\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: lower not found"
     ]
    }
   ],
   "source": [
    "# NEGATİF İNCELEME\n",
    "nr = data['text'][16]\n",
    "print(nr)\n",
    "print(\"Actual Rating: \",data['stars'][23])\n",
    "nr_t = vocab.transform([nr])\n",
    "print(\"Predicted Rating:\")\n",
    "mlp.predict(nr_t)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Görüldüğü gibi, actual rating ve predicted rating birbirini desteklemiyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = data['stars'].value_counts()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yukarıdan, tahminlerin olumlu eleştirilere yönelik olduğunu, \n",
    "Veri setinin olumsuz yorumlara kıyasla daha olumlu yorumlara sahip olduğunu görebiliriz. \n",
    "Bu sebepten ötürü veri kümesinde bias problemi oluştuğunu düşünmek mantıklıdır, bu problem veri kümesini eşit sayıda incelemeye sahip olacak şekilde normalleştirerek    \n",
    "*böylece bias problemini ortadan kaldırılmış olur* düzeltilebilir. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sonuç olarak: \n",
    "Bu çalışmada, çeşitli makine öğrenimi algoritmaları kullanılarak ‘Yelp dataset’ veri kümesindeki inceleme derecelerinin tahmini ve duyarlılık analizi gösterilmiştir. Herhangi bir makine öğrenmesi modellemesi yapılmadan önce ilk olarak R ile keşifsel veri analizi yapılarak veri setine ilişkin içgörü oluşturuldu ve veriye ait önemli değişkenlere ve değişkenler arasındaki ilişkiye yer verildi. Uygulama aşamasında ise, ilk olarak python ile incelemenin (text değişkeninin) kelime uzunluğunu içeren “length” isimli değişken oluşturuldu. Ardından length ile ilgili analizler yapıldı ve yorumlandı. Ardından Yelp veri çerçevesinin yalnızca 1, 3 veya 5 yıldızlı incelemelerini içeren yeni bir veri çerçevesi oluşturuldu ve analizlere bu veri çerçevesi ile devam edildi. Features, Labels, stop words ve vektörleştirme ile ilgili detaylara yer verildikten sonra veriseti, train ve test olarak ikiye bölünerek modelleme aşamalarına geçildi. Modelleme aşamalarında Multilayer Perceptron, Multinomial Naive Bayes, XGBoost Classifier, Gradient Boosting Classifier, Support Vector Machine, Random Forest Classifier, Decision Tree, K Neighbor Classifier olmak üzere 8 farklı makine algoritması detaylı bir şekilde anlatıldı ve python ile uygulaması yapıldı. Ardından, en iyi score değerine sahip olan modelin Multilayer Perceptron(Çok Katmanlı Sınıflayıcı) olduğu saptandı ve böylece çok katmanlı sınıflandırıcı en iyi puana sahip olduğundan, rastgele bir pozitif incelemeyi, rastgele bir ortalama incelemeyi ve rastgele bir negatif incelemeyi tahmin etmek için kullanıldı.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
